import os
import torch
from torch.utils.data import DataLoader
from torch.optim import AdamW
from tqdm import tqdm
import pandas as pd

from stage3_dataset import Stage3Dataset
from stage3_model import Stage3NegligenceClassifier

# â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHECKPOINT_DIR = "./checkpoints4"
PF_PATH       = os.path.join(CHECKPOINT_DIR, "train_first_preds_ep43.pth")
PF_VAL_PATH   = os.path.join(CHECKPOINT_DIR, "val_first_preds_ep43.pth")

CHECKPOINT_DIR_2 = "./checkpoints4_result"
SECOND_PATH      = os.path.join(CHECKPOINT_DIR_2, "train_stage2_preds_ep42.pth")
SECOND_VAL_PATH  = os.path.join(CHECKPOINT_DIR_2, "val_stage2_preds_ep42.pth")

LABEL_CSV_PATH = "./train_data_grouped_with_class.csv"

# â”€â”€â”€ í•˜ì´í¼íŒŒë¼ë¯¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BATCH_SIZE = 32
NUM_EPOCHS = 30
LR         = 1e-4
WD         = 1e-4
DEVICE     = 'cuda' if torch.cuda.is_available() else 'cpu'

# â”€â”€â”€ ë°ì´í„°ì…‹ & ë¡œë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
train_ds = Stage3Dataset(PF_PATH,      SECOND_PATH,     LABEL_CSV_PATH)
val_ds   = Stage3Dataset(PF_VAL_PATH,  SECOND_VAL_PATH, LABEL_CSV_PATH)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)

# â”€â”€â”€ ëª¨ë¸ / ì˜µí‹°ë§ˆì´ì € / ì†ì‹¤í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model     = Stage3NegligenceClassifier(num_classes=11).to(DEVICE)
optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WD)
criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)

# â”€â”€â”€ ì²´í¬í¬ì¸íŠ¸ í´ë” & CSV íŒŒì¼ ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.makedirs(CHECKPOINT_DIR_2, exist_ok=True)
BEST_PATH    = os.path.join(CHECKPOINT_DIR_2, "stage3_best.pth")
METRICS_CSV  = os.path.join(CHECKPOINT_DIR_2, "stage3_metrics.csv")

# â”€â”€â”€ ê¸°ë¡ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
history = {
    "epoch": [],
    "train_loss": [], "train_acc": [],
    "val_loss": [],   "val_acc": []
}

best_val_acc = 0.0

for epoch in range(1, NUM_EPOCHS+1):
    # ---- Train ----
    model.train()
    total, correct, train_loss = 0, 0, 0
    for pf, feat, a, b, label in tqdm(train_loader, desc=f"[Epoch {epoch}] Train"):
        pf, feat, a, b, label = (x.to(DEVICE) for x in (pf, feat, a, b, label))
        logits = model(pf, feat, a, b)
        loss = criterion(logits, label)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item() * pf.size(0)
        pred = logits.argmax(dim=1)
        correct += (pred == label).sum().item()
        total += label.size(0)

    train_acc  = correct / total
    train_loss = train_loss / total

    # ---- Validation ----
    model.eval()
    val_total, val_correct, val_loss = 0, 0, 0
    with torch.no_grad():
        for pf, feat, a, b, label in val_loader:
            pf, feat, a, b, label = (x.to(DEVICE) for x in (pf, feat, a, b, label))
            logits = model(pf, feat, a, b)
            loss = criterion(logits, label)

            val_loss   += loss.item() * pf.size(0)
            pred        = logits.argmax(dim=1)
            val_correct += (pred == label).sum().item()
            val_total   += label.size(0)

    val_acc  = val_correct / val_total
    val_loss = val_loss / val_total

    print(f"[Epoch {epoch}] "
          f"Train Loss: {train_loss:.4f} | Acc: {train_acc:.3f} || "
          f"Val Loss: {val_loss:.4f} | Acc: {val_acc:.3f}")

    # ---- Best ëª¨ë¸ ì €ì¥ ----
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_acc': val_acc
        }, BEST_PATH)
        print(f"ğŸ‘‰ New best model saved (epoch {epoch}, val_acc {val_acc:.3f}) at\n   {BEST_PATH}")

    # ---- ë©”íŠ¸ë¦­ ê¸°ë¡ ----
    history["epoch"].append(epoch)
    history["train_loss"].append(train_loss)
    history["train_acc"].append(train_acc)
    history["val_loss"].append(val_loss)
    history["val_acc"].append(val_acc)

# â”€â”€â”€ CSVë¡œ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = pd.DataFrame(history)
df.to_csv(METRICS_CSV, index=False)
print(f"âœ… Saved training metrics to {METRICS_CSV}")
print(f"Training complete. Best Val Acc: {best_val_acc:.3f}")