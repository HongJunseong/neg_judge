{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 원본 CSV 불러오기\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "\n",
    "# video_id 컬럼 만들기\n",
    "df[\"video_id\"] = df[\"video_name_with_frame\"].apply(\n",
    "    lambda x: x.split(\"_frame_\")[0].replace(\".mp4\", \"\").replace(\".jpg\", \"\")\n",
    ")\n",
    "\n",
    "# 그룹화: video_id 기준으로 첫 번째 값만 사용 (모두 동일하다고 가정)\n",
    "grouped_df = df.groupby(\"video_id\").agg({\n",
    "    \"accident_negligence_rateA\": \"first\",\n",
    "    \"accident_negligence_rateB\": \"first\",\n",
    "    \"accident_object\": \"first\",\n",
    "    \"accident_place\": \"first\",\n",
    "    \"accident_place_feature\": \"first\",\n",
    "    \"vehicle_a_progress_info\": \"first\",\n",
    "    \"vehicle_b_progress_info\": \"first\",\n",
    "    \"filming_way\": \"first\",\n",
    "    \"video_point_of_view\": \"first\"\n",
    "}).reset_index()\n",
    "\n",
    "# 저장\n",
    "grouped_df.to_csv(\"train_data_grouped_with_info.csv\", index=False)\n",
    "print(\"그룹화된 데이터 저장 완료: train_data_grouped_with_info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_classes(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        return {int(line.strip().split()[1]) for line in f}\n",
    "\n",
    "\n",
    "feat_all = sorted(extract_classes(\"tsn_dataset/train_accident_place_feature.txt\")                 \n",
    "                | extract_classes(\"tsn_dataset/val_accident_place_feature.txt\")\n",
    "                | extract_classes(\"tsn_dataset/test_accident_place_feature.txt\"))  # train ∪ val ∪ test\n",
    "\n",
    "a_all = sorted(extract_classes(\"tsn_dataset/train_vehicle_a_progress_info.txt\")\n",
    "               | extract_classes(\"tsn_dataset/val_vehicle_a_progress_info.txt\")\n",
    "               | extract_classes(\"tsn_dataset/test_vehicle_a_progress_info.txt\"))\n",
    "\n",
    "b_all = sorted(extract_classes(\"tsn_dataset/train_vehicle_b_progress_info.txt\")\n",
    "               | extract_classes(\"tsn_dataset/val_vehicle_b_progress_info.txt\")\n",
    "               | extract_classes(\"tsn_dataset/test_vehicle_b_progress_info.txt\"))\n",
    "\n",
    "print(\"전체 feat 클래스 수:\", len(feat_all))\n",
    "print(\"전체 A 클래스 수:\", len(a_all))\n",
    "print(\"전체 B 클래스 수:\", len(b_all))\n",
    "\n",
    "\n",
    "feat_to_new = {orig:i for i, orig in enumerate(feat_all)}\n",
    "a_to_new = {orig:i for i, orig in enumerate(a_all)}\n",
    "b_to_new = {orig:i for i, orig in enumerate(b_all)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcee054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_labels(in_path, out_path, mapping):\n",
    "    with open(in_path) as fin, open(out_path, \"w\") as fout:\n",
    "        for line in fin:\n",
    "            vid, orig = line.strip().split()\n",
    "            orig = int(orig)\n",
    "            if orig not in mapping:\n",
    "                continue\n",
    "            new = mapping[orig]\n",
    "            fout.write(f\"{vid} {new}\\n\")\n",
    "\n",
    "# train\n",
    "remap_labels(\n",
    "    \"tsn_dataset/train_accident_place_feature.txt\",\n",
    "    \"tsn_dataset/train_accident_place_feature_mapped.txt\",\n",
    "    feat_to_new\n",
    ")\n",
    "\n",
    "remap_labels(\n",
    "    \"tsn_dataset/train_vehicle_a_progress_info.txt\",\n",
    "    \"tsn_dataset/train_vehicle_a_progress_info_mapped.txt\",\n",
    "    a_to_new\n",
    ")\n",
    "\n",
    "remap_labels(\n",
    "    \"tsn_dataset/train_vehicle_b_progress_info.txt\",\n",
    "    \"tsn_dataset/train_vehicle_b_progress_info_mapped.txt\",\n",
    "    b_to_new\n",
    ")\n",
    "\n",
    "# val\n",
    "remap_labels(\n",
    "    \"tsn_dataset/val_accident_place_feature.txt\",\n",
    "    \"tsn_dataset/val_accident_place_feature_mapped.txt\",\n",
    "    feat_to_new\n",
    ")\n",
    "\n",
    "remap_labels(\n",
    "    \"tsn_dataset/val_vehicle_a_progress_info.txt\",\n",
    "    \"tsn_dataset/val_vehicle_a_progress_info_mapped.txt\",\n",
    "    a_to_new\n",
    ")\n",
    "\n",
    "remap_labels(\n",
    "    \"tsn_dataset/val_vehicle_b_progress_info.txt\",\n",
    "    \"tsn_dataset/val_vehicle_b_progress_info_mapped.txt\",\n",
    "    b_to_new\n",
    ")\n",
    "\n",
    "# test\n",
    "remap_labels(\n",
    "    \"tsn_dataset/test_accident_place_feature.txt\",\n",
    "    \"tsn_dataset/test_accident_place_feature_mapped.txt\",\n",
    "    feat_to_new\n",
    ")\n",
    "\n",
    "remap_labels(\n",
    "    \"tsn_dataset/test_vehicle_a_progress_info.txt\",\n",
    "    \"tsn_dataset/test_vehicle_a_progress_info_mapped.txt\",\n",
    "    a_to_new\n",
    ")\n",
    "\n",
    "remap_labels(\n",
    "    \"tsn_dataset/test_vehicle_b_progress_info.txt\",\n",
    "    \"tsn_dataset/test_vehicle_b_progress_info_mapped.txt\",\n",
    "    b_to_new\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
